{"ast":null,"code":"import _asyncToGenerator from \"E:/Important/FIT/project-front-end/FrontEnd_ThayLong_Nhom-21/app-chat/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport { copyFromChannel } from '../helpers/copy-from-channel';\nimport { copyToChannel } from '../helpers/copy-to-channel';\nimport { createNestedArrays } from '../helpers/create-nested-arrays';\nimport { getAudioNodeConnections } from '../helpers/get-audio-node-connections';\nimport { getAudioWorkletProcessor } from '../helpers/get-audio-worklet-processor';\nimport { isOwnedByContext } from '../helpers/is-owned-by-context';\n\nconst processBuffer = /*#__PURE__*/function () {\n  var _ref = _asyncToGenerator(function* (proxy, renderedBuffer, nativeOfflineAudioContext, options, outputChannelCount, processorConstructor, exposeCurrentFrameAndCurrentTime) {\n    // Ceil the length to the next full render quantum.\n    // Bug #17: Safari does not yet expose the length.\n    const length = renderedBuffer === null ? Math.ceil(proxy.context.length / 128) * 128 : renderedBuffer.length;\n    const numberOfInputChannels = options.channelCount * options.numberOfInputs;\n    const numberOfOutputChannels = outputChannelCount.reduce((sum, value) => sum + value, 0);\n    const processedBuffer = numberOfOutputChannels === 0 ? null : nativeOfflineAudioContext.createBuffer(numberOfOutputChannels, length, nativeOfflineAudioContext.sampleRate);\n\n    if (processorConstructor === undefined) {\n      throw new Error('Missing the processor constructor.');\n    }\n\n    const audioNodeConnections = getAudioNodeConnections(proxy);\n    const audioWorkletProcessor = yield getAudioWorkletProcessor(nativeOfflineAudioContext, proxy);\n    const inputs = createNestedArrays(options.numberOfInputs, options.channelCount);\n    const outputs = createNestedArrays(options.numberOfOutputs, outputChannelCount);\n    const parameters = Array.from(proxy.parameters.keys()).reduce((prmtrs, name) => ({ ...prmtrs,\n      [name]: new Float32Array(128)\n    }), {});\n\n    for (let i = 0; i < length; i += 128) {\n      if (options.numberOfInputs > 0 && renderedBuffer !== null) {\n        for (let j = 0; j < options.numberOfInputs; j += 1) {\n          for (let k = 0; k < options.channelCount; k += 1) {\n            copyFromChannel(renderedBuffer, inputs[j], k, k, i);\n          }\n        }\n      }\n\n      if (processorConstructor.parameterDescriptors !== undefined && renderedBuffer !== null) {\n        processorConstructor.parameterDescriptors.forEach(({\n          name\n        }, index) => {\n          copyFromChannel(renderedBuffer, parameters, name, numberOfInputChannels + index, i);\n        });\n      }\n\n      for (let j = 0; j < options.numberOfInputs; j += 1) {\n        for (let k = 0; k < outputChannelCount[j]; k += 1) {\n          // The byteLength will be 0 when the ArrayBuffer was transferred.\n          if (outputs[j][k].byteLength === 0) {\n            outputs[j][k] = new Float32Array(128);\n          }\n        }\n      }\n\n      try {\n        const potentiallyEmptyInputs = inputs.map((input, index) => {\n          if (audioNodeConnections.activeInputs[index].size === 0) {\n            return [];\n          }\n\n          return input;\n        });\n        const activeSourceFlag = exposeCurrentFrameAndCurrentTime(i / nativeOfflineAudioContext.sampleRate, nativeOfflineAudioContext.sampleRate, () => audioWorkletProcessor.process(potentiallyEmptyInputs, outputs, parameters));\n\n        if (processedBuffer !== null) {\n          for (let j = 0, outputChannelSplitterNodeOutput = 0; j < options.numberOfOutputs; j += 1) {\n            for (let k = 0; k < outputChannelCount[j]; k += 1) {\n              copyToChannel(processedBuffer, outputs[j], k, outputChannelSplitterNodeOutput + k, i);\n            }\n\n            outputChannelSplitterNodeOutput += outputChannelCount[j];\n          }\n        }\n\n        if (!activeSourceFlag) {\n          break;\n        }\n      } catch (error) {\n        proxy.dispatchEvent(new ErrorEvent('processorerror', {\n          colno: error.colno,\n          filename: error.filename,\n          lineno: error.lineno,\n          message: error.message\n        }));\n        break;\n      }\n    }\n\n    return processedBuffer;\n  });\n\n  return function processBuffer(_x, _x2, _x3, _x4, _x5, _x6, _x7) {\n    return _ref.apply(this, arguments);\n  };\n}();\n\nexport const createAudioWorkletNodeRendererFactory = (connectAudioParam, connectMultipleOutputs, createNativeAudioBufferSourceNode, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, deleteUnrenderedAudioWorkletNode, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getNativeAudioNode, nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext) => {\n  return (name, options, processorConstructor) => {\n    const renderedNativeAudioNodes = new WeakMap();\n    let processedBufferPromise = null;\n\n    const createAudioNode = /*#__PURE__*/function () {\n      var _ref2 = _asyncToGenerator(function* (proxy, nativeOfflineAudioContext, trace) {\n        let nativeAudioWorkletNode = getNativeAudioNode(proxy);\n        let nativeOutputNodes = null;\n        const nativeAudioWorkletNodeIsOwnedByContext = isOwnedByContext(nativeAudioWorkletNode, nativeOfflineAudioContext);\n        const outputChannelCount = Array.isArray(options.outputChannelCount) ? options.outputChannelCount : Array.from(options.outputChannelCount); // Bug #61: Only Chrome, Edge, Firefox & Opera have an implementation of the AudioWorkletNode yet.\n\n        if (nativeAudioWorkletNodeConstructor === null) {\n          const numberOfOutputChannels = outputChannelCount.reduce((sum, value) => sum + value, 0);\n          const outputChannelSplitterNode = createNativeChannelSplitterNode(nativeOfflineAudioContext, {\n            channelCount: Math.max(1, numberOfOutputChannels),\n            channelCountMode: 'explicit',\n            channelInterpretation: 'discrete',\n            numberOfOutputs: Math.max(1, numberOfOutputChannels)\n          });\n          const outputChannelMergerNodes = [];\n\n          for (let i = 0; i < proxy.numberOfOutputs; i += 1) {\n            outputChannelMergerNodes.push(createNativeChannelMergerNode(nativeOfflineAudioContext, {\n              channelCount: 1,\n              channelCountMode: 'explicit',\n              channelInterpretation: 'speakers',\n              numberOfInputs: outputChannelCount[i]\n            }));\n          }\n\n          const outputGainNode = createNativeGainNode(nativeOfflineAudioContext, {\n            channelCount: options.channelCount,\n            channelCountMode: options.channelCountMode,\n            channelInterpretation: options.channelInterpretation,\n            gain: 1\n          });\n          outputGainNode.connect = connectMultipleOutputs.bind(null, outputChannelMergerNodes);\n          outputGainNode.disconnect = disconnectMultipleOutputs.bind(null, outputChannelMergerNodes);\n          nativeOutputNodes = [outputChannelSplitterNode, outputChannelMergerNodes, outputGainNode];\n        } else if (!nativeAudioWorkletNodeIsOwnedByContext) {\n          nativeAudioWorkletNode = new nativeAudioWorkletNodeConstructor(nativeOfflineAudioContext, name);\n        }\n\n        renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeOutputNodes === null ? nativeAudioWorkletNode : nativeOutputNodes[2]);\n\n        if (nativeOutputNodes !== null) {\n          if (processedBufferPromise === null) {\n            if (processorConstructor === undefined) {\n              throw new Error('Missing the processor constructor.');\n            }\n\n            if (nativeOfflineAudioContextConstructor === null) {\n              throw new Error('Missing the native OfflineAudioContext constructor.');\n            } // Bug #47: The AudioDestinationNode in Safari gets not initialized correctly.\n\n\n            const numberOfInputChannels = proxy.channelCount * proxy.numberOfInputs;\n            const numberOfParameters = processorConstructor.parameterDescriptors === undefined ? 0 : processorConstructor.parameterDescriptors.length;\n            const numberOfChannels = numberOfInputChannels + numberOfParameters;\n\n            const renderBuffer = /*#__PURE__*/function () {\n              var _ref3 = _asyncToGenerator(function* () {\n                const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(numberOfChannels, // Ceil the length to the next full render quantum.\n                // Bug #17: Safari does not yet expose the length.\n                Math.ceil(proxy.context.length / 128) * 128, nativeOfflineAudioContext.sampleRate);\n                const gainNodes = [];\n                const inputChannelSplitterNodes = [];\n\n                for (let i = 0; i < options.numberOfInputs; i += 1) {\n                  gainNodes.push(createNativeGainNode(partialOfflineAudioContext, {\n                    channelCount: options.channelCount,\n                    channelCountMode: options.channelCountMode,\n                    channelInterpretation: options.channelInterpretation,\n                    gain: 1\n                  }));\n                  inputChannelSplitterNodes.push(createNativeChannelSplitterNode(partialOfflineAudioContext, {\n                    channelCount: options.channelCount,\n                    channelCountMode: 'explicit',\n                    channelInterpretation: 'discrete',\n                    numberOfOutputs: options.channelCount\n                  }));\n                }\n\n                const constantSourceNodes = yield Promise.all(Array.from(proxy.parameters.values()).map( /*#__PURE__*/function () {\n                  var _ref4 = _asyncToGenerator(function* (audioParam) {\n                    const constantSourceNode = createNativeConstantSourceNode(partialOfflineAudioContext, {\n                      channelCount: 1,\n                      channelCountMode: 'explicit',\n                      channelInterpretation: 'discrete',\n                      offset: audioParam.value\n                    });\n                    yield renderAutomation(partialOfflineAudioContext, audioParam, constantSourceNode.offset, trace);\n                    return constantSourceNode;\n                  });\n\n                  return function (_x11) {\n                    return _ref4.apply(this, arguments);\n                  };\n                }()));\n                const inputChannelMergerNode = createNativeChannelMergerNode(partialOfflineAudioContext, {\n                  channelCount: 1,\n                  channelCountMode: 'explicit',\n                  channelInterpretation: 'speakers',\n                  numberOfInputs: Math.max(1, numberOfInputChannels + numberOfParameters)\n                });\n\n                for (let i = 0; i < options.numberOfInputs; i += 1) {\n                  gainNodes[i].connect(inputChannelSplitterNodes[i]);\n\n                  for (let j = 0; j < options.channelCount; j += 1) {\n                    inputChannelSplitterNodes[i].connect(inputChannelMergerNode, j, i * options.channelCount + j);\n                  }\n                }\n\n                for (const [index, constantSourceNode] of constantSourceNodes.entries()) {\n                  constantSourceNode.connect(inputChannelMergerNode, 0, numberOfInputChannels + index);\n                  constantSourceNode.start(0);\n                }\n\n                inputChannelMergerNode.connect(partialOfflineAudioContext.destination);\n                yield Promise.all(gainNodes.map(gainNode => renderInputsOfAudioNode(proxy, partialOfflineAudioContext, gainNode, trace)));\n                return renderNativeOfflineAudioContext(partialOfflineAudioContext);\n              });\n\n              return function renderBuffer() {\n                return _ref3.apply(this, arguments);\n              };\n            }();\n\n            processedBufferPromise = processBuffer(proxy, numberOfChannels === 0 ? null : yield renderBuffer(), nativeOfflineAudioContext, options, outputChannelCount, processorConstructor, exposeCurrentFrameAndCurrentTime);\n          }\n\n          const processedBuffer = yield processedBufferPromise;\n          const audioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, {\n            buffer: null,\n            channelCount: 2,\n            channelCountMode: 'max',\n            channelInterpretation: 'speakers',\n            loop: false,\n            loopEnd: 0,\n            loopStart: 0,\n            playbackRate: 1\n          });\n          const [outputChannelSplitterNode, outputChannelMergerNodes, outputGainNode] = nativeOutputNodes;\n\n          if (processedBuffer !== null) {\n            audioBufferSourceNode.buffer = processedBuffer;\n            audioBufferSourceNode.start(0);\n          }\n\n          audioBufferSourceNode.connect(outputChannelSplitterNode);\n\n          for (let i = 0, outputChannelSplitterNodeOutput = 0; i < proxy.numberOfOutputs; i += 1) {\n            const outputChannelMergerNode = outputChannelMergerNodes[i];\n\n            for (let j = 0; j < outputChannelCount[i]; j += 1) {\n              outputChannelSplitterNode.connect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);\n            }\n\n            outputChannelSplitterNodeOutput += outputChannelCount[i];\n          }\n\n          return outputGainNode;\n        }\n\n        if (!nativeAudioWorkletNodeIsOwnedByContext) {\n          for (const [nm, audioParam] of proxy.parameters.entries()) {\n            yield renderAutomation(nativeOfflineAudioContext, audioParam, // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.\n            nativeAudioWorkletNode.parameters.get(nm), trace);\n          }\n        } else {\n          for (const [nm, audioParam] of proxy.parameters.entries()) {\n            yield connectAudioParam(nativeOfflineAudioContext, audioParam, // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.\n            nativeAudioWorkletNode.parameters.get(nm), trace);\n          }\n        }\n\n        yield renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioWorkletNode, trace);\n        return nativeAudioWorkletNode;\n      });\n\n      return function createAudioNode(_x8, _x9, _x10) {\n        return _ref2.apply(this, arguments);\n      };\n    }();\n\n    return {\n      render(proxy, nativeOfflineAudioContext, trace) {\n        deleteUnrenderedAudioWorkletNode(nativeOfflineAudioContext, proxy);\n        const renderedNativeAudioWorkletNodeOrGainNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);\n\n        if (renderedNativeAudioWorkletNodeOrGainNode !== undefined) {\n          return Promise.resolve(renderedNativeAudioWorkletNodeOrGainNode);\n        }\n\n        return createAudioNode(proxy, nativeOfflineAudioContext, trace);\n      }\n\n    };\n  };\n}; //# sourceMappingURL=audio-worklet-node-renderer-factory.js.map","map":null,"metadata":{},"sourceType":"module"}