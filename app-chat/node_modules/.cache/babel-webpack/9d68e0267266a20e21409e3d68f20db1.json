{"ast":null,"code":"import _asyncToGenerator from \"E:/Important/FIT/project-front-end/FrontEnd_ThayLong_Nhom-21/app-chat/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport { encode, instantiate } from 'media-encoder-host';\nimport { addRecorderAudioWorkletModule, createRecorderAudioWorkletNode } from 'recorder-audio-worklet';\nimport { AudioBuffer, AudioBufferSourceNode, AudioWorkletNode, MediaStreamAudioSourceNode, MinimalAudioContext, addAudioWorkletModule } from 'standardized-audio-context';\nconst ERROR_MESSAGE = 'Missing AudioWorklet support. Maybe this is not running in a secure context.'; // @todo This should live in a separate file.\n\nconst createPromisedAudioNodesEncoderIdAndPort = /*#__PURE__*/function () {\n  var _ref = _asyncToGenerator(function* (audioBuffer, audioContext, channelCount, mediaStream, mimeType) {\n    const {\n      encoderId,\n      port\n    } = yield instantiate(mimeType, audioContext.sampleRate);\n\n    if (AudioWorkletNode === undefined) {\n      throw new Error(ERROR_MESSAGE);\n    }\n\n    const audioBufferSourceNode = new AudioBufferSourceNode(audioContext, {\n      buffer: audioBuffer\n    });\n    const mediaStreamAudioSourceNode = new MediaStreamAudioSourceNode(audioContext, {\n      mediaStream\n    });\n    const recorderAudioWorkletNode = createRecorderAudioWorkletNode(AudioWorkletNode, audioContext, {\n      channelCount\n    });\n    return {\n      audioBufferSourceNode,\n      encoderId,\n      mediaStreamAudioSourceNode,\n      port,\n      recorderAudioWorkletNode\n    };\n  });\n\n  return function createPromisedAudioNodesEncoderIdAndPort(_x, _x2, _x3, _x4, _x5) {\n    return _ref.apply(this, arguments);\n  };\n}();\n\nexport const createWebAudioMediaRecorderFactory = (createBlobEvent, createInvalidModificationError, createInvalidStateError, createNotSupportedError) => {\n  return (eventTarget, mediaStream, mimeType) => {\n    const audioContext = new MinimalAudioContext({\n      latencyHint: 'playback'\n    });\n    const length = Math.max(512, Math.ceil(audioContext.baseLatency * audioContext.sampleRate));\n    const audioBuffer = new AudioBuffer({\n      length,\n      sampleRate: audioContext.sampleRate\n    });\n    const promisedAudioWorkletModule = addRecorderAudioWorkletModule(url => {\n      if (addAudioWorkletModule === undefined) {\n        throw new Error(ERROR_MESSAGE);\n      }\n\n      return addAudioWorkletModule(audioContext, url);\n    });\n    let abortRecording = null;\n    let intervalId = null;\n    let promisedAudioNodesAndEncoderId = null;\n    let promisedPartialRecording = null;\n\n    const dispatchDataAvailableEvent = arrayBuffers => {\n      eventTarget.dispatchEvent(createBlobEvent('dataavailable', {\n        data: new Blob(arrayBuffers, {\n          type: mimeType\n        })\n      }));\n    };\n\n    const requestNextPartialRecording = /*#__PURE__*/function () {\n      var _ref2 = _asyncToGenerator(function* (encoderId, timeslice) {\n        dispatchDataAvailableEvent(yield encode(encoderId, timeslice));\n\n        if (promisedAudioNodesAndEncoderId !== null) {\n          promisedPartialRecording = requestNextPartialRecording(encoderId, timeslice);\n        }\n      });\n\n      return function requestNextPartialRecording(_x6, _x7) {\n        return _ref2.apply(this, arguments);\n      };\n    }();\n\n    const stop = () => {\n      if (promisedAudioNodesAndEncoderId === null) {\n        return;\n      }\n\n      if (abortRecording !== null) {\n        mediaStream.removeEventListener('addtrack', abortRecording);\n        mediaStream.removeEventListener('removetrack', abortRecording);\n      }\n\n      if (intervalId !== null) {\n        clearTimeout(intervalId);\n      }\n\n      if (promisedPartialRecording !== null) {\n        promisedPartialRecording.catch(() => {\n          /* @todo Only catch the errors caused by a duplicate call to encode. */\n        });\n        promisedPartialRecording = null;\n      }\n\n      promisedAudioNodesAndEncoderId.then( /*#__PURE__*/function () {\n        var _ref3 = _asyncToGenerator(function* ({\n          encoderId,\n          mediaStreamAudioSourceNode,\n          recorderAudioWorkletNode\n        }) {\n          yield recorderAudioWorkletNode.stop();\n          mediaStreamAudioSourceNode.disconnect(recorderAudioWorkletNode);\n          dispatchDataAvailableEvent(yield encode(encoderId, null));\n          eventTarget.dispatchEvent(new Event('stop'));\n        });\n\n        return function (_x8) {\n          return _ref3.apply(this, arguments);\n        };\n      }());\n      promisedAudioNodesAndEncoderId = null;\n    };\n\n    return {\n      get mimeType() {\n        return mimeType;\n      },\n\n      get state() {\n        return promisedAudioNodesAndEncoderId === null ? 'inactive' : 'recording';\n      },\n\n      start(timeslice) {\n        var _a;\n\n        if (promisedAudioNodesAndEncoderId !== null) {\n          throw createInvalidStateError();\n        }\n\n        if (mediaStream.getVideoTracks().length > 0) {\n          throw createNotSupportedError();\n        }\n\n        const audioTracks = mediaStream.getAudioTracks();\n        const channelCount = audioTracks.length === 0 ? 2 : (_a = audioTracks[0].getSettings().channelCount) !== null && _a !== void 0 ? _a : 2;\n        promisedAudioNodesAndEncoderId = Promise.all([audioContext.resume(), promisedAudioWorkletModule.then(() => createPromisedAudioNodesEncoderIdAndPort(audioBuffer, audioContext, channelCount, mediaStream, mimeType))]).then( /*#__PURE__*/function () {\n          var _ref4 = _asyncToGenerator(function* ([, {\n            audioBufferSourceNode,\n            encoderId,\n            mediaStreamAudioSourceNode,\n            port,\n            recorderAudioWorkletNode\n          }]) {\n            mediaStreamAudioSourceNode.connect(recorderAudioWorkletNode);\n            yield new Promise(resolve => {\n              audioBufferSourceNode.onended = resolve;\n              audioBufferSourceNode.connect(recorderAudioWorkletNode);\n              audioBufferSourceNode.start(audioContext.currentTime + length / audioContext.sampleRate);\n            });\n            audioBufferSourceNode.disconnect(recorderAudioWorkletNode);\n            yield recorderAudioWorkletNode.record(port);\n\n            if (timeslice !== undefined) {\n              promisedPartialRecording = requestNextPartialRecording(encoderId, timeslice);\n            }\n\n            return {\n              encoderId,\n              mediaStreamAudioSourceNode,\n              recorderAudioWorkletNode\n            };\n          });\n\n          return function (_x9) {\n            return _ref4.apply(this, arguments);\n          };\n        }());\n        const tracks = mediaStream.getTracks();\n\n        abortRecording = () => {\n          stop();\n          eventTarget.dispatchEvent(new ErrorEvent('error', {\n            error: createInvalidModificationError()\n          }));\n        };\n\n        mediaStream.addEventListener('addtrack', abortRecording);\n        mediaStream.addEventListener('removetrack', abortRecording);\n        intervalId = setInterval(() => {\n          const currentTracks = mediaStream.getTracks();\n\n          if ((currentTracks.length !== tracks.length || currentTracks.some((track, index) => track !== tracks[index])) && abortRecording !== null) {\n            abortRecording();\n          }\n        }, 1000);\n      },\n\n      stop\n    };\n  };\n}; //# sourceMappingURL=web-audio-media-recorder.js.map","map":null,"metadata":{},"sourceType":"module"}